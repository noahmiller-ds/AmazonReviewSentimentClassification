{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a8a54d",
   "metadata": {},
   "source": [
    "# Noah Miller GitHub Python Project 2: Natural Language Processing  Amazon Product Reviews\n",
    "\n",
    "### Note: This project is adapted from a project from one of my graduate classes with ideas and code borrowed from other souces. I will make citations in the code and at the end of this document.\n",
    "\n",
    "In this notebook, we will be investigating Amazon product reviews. The dataset in question comes from https://www.kaggle.com/kritanjalijain/amazon-reviews?select=train.csv and consists of a spreadsheet containing a review, the review title, and whether or not the review is positive (denoted by a 2) or negative (denoted by a 1). The business application of this project is to identify terms associated with good reviews, terms associated with bad reviews, and whether or not we can use machine learning methods to identify if a review is good or bad. We can use this information to suggest the sale of an alternative product in the case of a bad review. Likewise, we can use this information to suggest more of the same or similar products to users who leave good reviews.\n",
    "\n",
    "\n",
    "## Step 1: Data Importing and Preprocessing\n",
    "\n",
    "In this step, let's first view our data frame before any preprocessing takes place. For the sake of speed and computational resources, we will limit our training data to only 500,000 of the original 3.6 million samples. We will sample these observations randomly to ensure the data set is not biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c14002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91242</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Signs\" is the most hideous sci-fi film I ever...</td>\n",
       "      <td>This was the most disappointing sci-fi film I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62299</th>\n",
       "      <td>1</td>\n",
       "      <td>Mukluks</td>\n",
       "      <td>Comfy, but not made as well as I hoped. Socks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110813</th>\n",
       "      <td>1</td>\n",
       "      <td>Not that great</td>\n",
       "      <td>Barbara Delinski is a great author, but this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120160</th>\n",
       "      <td>1</td>\n",
       "      <td>Booring Bugggery</td>\n",
       "      <td>Buns! Buggery! Brutality! Booring! The littery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117321</th>\n",
       "      <td>1</td>\n",
       "      <td>HOUSEBOY</td>\n",
       "      <td>THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                              Title  \\\n",
       "91242           1  \"Signs\" is the most hideous sci-fi film I ever...   \n",
       "62299           1                                            Mukluks   \n",
       "110813          1                                     Not that great   \n",
       "120160          1                                   Booring Bugggery   \n",
       "117321          1                                           HOUSEBOY   \n",
       "\n",
       "                                                   Review  \n",
       "91242   This was the most disappointing sci-fi film I ...  \n",
       "62299   Comfy, but not made as well as I hoped. Socks ...  \n",
       "110813  Barbara Delinski is a great author, but this b...  \n",
       "120160  Buns! Buggery! Brutality! Booring! The littery...  \n",
       "117321  THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Filters out red boxes due to warnings\n",
    "import pandas as pd  # Great for manipulating data frames\n",
    "from dask import dataframe as dd  # I found this was faster for reading in csv files\n",
    "#pd.options.mode.chained_assignment = None  # Disables chained assignments\n",
    "# The solution above helped me assign one column to be another one and comes from\n",
    "# https://stackoverflow.com/questions/49728421/pandas-dataframe-settingwithcopywarning-a-value-is-trying-to-be-set-on-a-copy\n",
    "import numpy as np  # Great for numerical manipulation\n",
    "import nltk  # Natural lanuage toolkit\n",
    "from nltk.corpus import stopwords, wordnet  # For preprocessing our data\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer  # For analyzing sentiments later on\n",
    "import multiprocess as mp  # Similar to multiprocessING, but just works better for Jupyter Notebook\n",
    "\n",
    "amazon_reviews = dd.read_csv(\"/Users/noahmiller/Downloads/train.csv\", header=None)  # Reading in through Dask is a little faster\n",
    "amazon_reviews = amazon_reviews.compute()  # Turns Dask data frame into Pandas data frame\n",
    "amazon_reviews = amazon_reviews.rename(columns={0: \"Sentiment\", 1:\"Title\",2:\"Review\"})  # Had to assign these manually\n",
    "amazon_reviews = amazon_reviews.dropna()  # Removes null values\n",
    "amazon_reviews = amazon_reviews.sample(n=500_000, random_state=123)  # Using 500,000 samples; the entire set was too much, even for my gaming PC with 6 cores and 32 GB of RAM. \n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa1e97",
   "metadata": {},
   "source": [
    "With these records read in and in a well-structured format, we can begin to process the data. First, we can reset the index of this data set. Observe that the index of the data frame above above has no discernable order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa91f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Signs\" is the most hideous sci-fi film I ever...</td>\n",
       "      <td>This was the most disappointing sci-fi film I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mukluks</td>\n",
       "      <td>Comfy, but not made as well as I hoped. Socks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Not that great</td>\n",
       "      <td>Barbara Delinski is a great author, but this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Booring Bugggery</td>\n",
       "      <td>Buns! Buggery! Brutality! Booring! The littery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>HOUSEBOY</td>\n",
       "      <td>THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                              Title  \\\n",
       "0          1  \"Signs\" is the most hideous sci-fi film I ever...   \n",
       "1          1                                            Mukluks   \n",
       "2          1                                     Not that great   \n",
       "3          1                                   Booring Bugggery   \n",
       "4          1                                           HOUSEBOY   \n",
       "\n",
       "                                              Review  \n",
       "0  This was the most disappointing sci-fi film I ...  \n",
       "1  Comfy, but not made as well as I hoped. Socks ...  \n",
       "2  Barbara Delinski is a great author, but this b...  \n",
       "3  Buns! Buggery! Brutality! Booring! The littery...  \n",
       "4  THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews = amazon_reviews.reset_index(drop=True)\n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04491c",
   "metadata": {},
   "source": [
    "This data frame is a lot more simple than before. We can make it even more simple, however, by considering sentiments of 1 to be Negative and by considering sentiments of 2 to be Positive. For this, it's easy enough to just use a lamba function on the desired column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e770ff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>\"Signs\" is the most hideous sci-fi film I ever...</td>\n",
       "      <td>This was the most disappointing sci-fi film I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Mukluks</td>\n",
       "      <td>Comfy, but not made as well as I hoped. Socks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Not that great</td>\n",
       "      <td>Barbara Delinski is a great author, but this b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Booring Bugggery</td>\n",
       "      <td>Buns! Buggery! Brutality! Booring! The littery...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>HOUSEBOY</td>\n",
       "      <td>THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Title  \\\n",
       "0  Negative  \"Signs\" is the most hideous sci-fi film I ever...   \n",
       "1  Negative                                            Mukluks   \n",
       "2  Negative                                     Not that great   \n",
       "3  Negative                                   Booring Bugggery   \n",
       "4  Negative                                           HOUSEBOY   \n",
       "\n",
       "                                              Review  \n",
       "0  This was the most disappointing sci-fi film I ...  \n",
       "1  Comfy, but not made as well as I hoped. Socks ...  \n",
       "2  Barbara Delinski is a great author, but this b...  \n",
       "3  Buns! Buggery! Brutality! Booring! The littery...  \n",
       "4  THIS MOVIE IS FAIR. ENTERTAINING BUT NOT A GRE...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_reviews['Sentiment'] = amazon_reviews['Sentiment'].map(lambda x: \"Negative\" if x==1 else \"Positive\")\n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec56b0",
   "metadata": {},
   "source": [
    "Observe that the sentiment column now consists of the words \"Negative\" and \"Positive\" to denote the sentiment of a review.\n",
    "\n",
    "This next cell is where a lot of the preprocessing takes place. The function below will, in order:\n",
    "* Remove puncutation from the columns\n",
    "* Remove non-alphanumeric characters from the columns\n",
    "* Convert the columns to lowercase\n",
    "* Remove stopwords from the sentence\n",
    "\n",
    "Likewise, I'd added in some additional logic which will allow Python to perform this processing in parallel. I have done this through the *multiprocess* module. That's not a typo; *multiprocess* is a fork of the *multiprocessing* module which just works better for Jupyter Notebooks, like this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda01ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>signs hideous scifi film ever watched</td>\n",
       "      <td>disappointing scifi film ever watchedyou alien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>mukluks</td>\n",
       "      <td>comfy made well hoped socks different sizes te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>great</td>\n",
       "      <td>barbara delinski great author book one worst c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>booring bugggery</td>\n",
       "      <td>buns buggery brutality booring littery device ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>houseboy</td>\n",
       "      <td>movie fair entertaining great movie looking mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                  Title  \\\n",
       "0  Negative  signs hideous scifi film ever watched   \n",
       "1  Negative                                mukluks   \n",
       "2  Negative                                  great   \n",
       "3  Negative                       booring bugggery   \n",
       "4  Negative                               houseboy   \n",
       "\n",
       "                                              Review  \n",
       "0  disappointing scifi film ever watchedyou alien...  \n",
       "1  comfy made well hoped socks different sizes te...  \n",
       "2  barbara delinski great author book one worst c...  \n",
       "3  buns buggery brutality booring littery device ...  \n",
       "4  movie fair entertaining great movie looking mo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Credit for parts of this InputProcessing function go to \n",
    "# https://erleem.medium.com/nlp-complete-sentiment-analysis-on-amazon-reviews-374e4fea9976\n",
    "# This is where I got the parts for removing non-alphanumeric, converting to lowercase, and removing stopwords\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "def InputProcessing(raw_input):\n",
    "    # Removing punctuation\n",
    "    raw_input = raw_input.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Removing non-alphanumeric characters from string\n",
    "    raw_input = raw_input.replace('[^a-zA-Z0-9 ]', '')\n",
    "    # Converting to lowercase\n",
    "    raw_input = raw_input.lower()\n",
    "    raw_input = raw_input.split()\n",
    "    # Remove stopwords\n",
    "    raw_input = [item for item in raw_input if item not in stopwords_list]\n",
    "    clean_output = ' '.join([str(elem) for elem in raw_input])\n",
    "    return clean_output\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['Review'] = pool.map(InputProcessing, amazon_reviews['Review'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['Title'] = pool.map(InputProcessing, amazon_reviews['Title'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d447b85",
   "metadata": {},
   "source": [
    "Now that our text has been altered to be cleaner, let's try another fundamental preprocessing step. Next, we'll lemmatize the words in our data set. This transforms them into smaller root words, making columns less unique which could help our models determine if they are positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfb1a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>sign hideous scifi film ever watch</td>\n",
       "      <td>disappoint scifi film ever watchedyou alien te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>mukluks</td>\n",
       "      <td>comfy make well hop sock different size tend t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>great</td>\n",
       "      <td>barbara delinski great author book one bad cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>booring bugggery</td>\n",
       "      <td>bun buggery brutality booring littery device u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>houseboy</td>\n",
       "      <td>movie fair entertain great movie look movie wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                               Title  \\\n",
       "0  Negative  sign hideous scifi film ever watch   \n",
       "1  Negative                             mukluks   \n",
       "2  Negative                               great   \n",
       "3  Negative                    booring bugggery   \n",
       "4  Negative                            houseboy   \n",
       "\n",
       "                                              Review  \n",
       "0  disappoint scifi film ever watchedyou alien te...  \n",
       "1  comfy make well hop sock different size tend t...  \n",
       "2  barbara delinski great author book one bad cou...  \n",
       "3  bun buggery brutality booring littery device u...  \n",
       "4  movie fair entertain great movie look movie wo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All credit for this lemmatization function goes to https://erleem.medium.com/nlp-complete-sentiment-analysis-on-amazon-reviews-374e4fea9976\n",
    "# I, however, introduced the parallelization to this function\n",
    "# Note: This may take a VERY long time so parallelization was necessary\n",
    "\n",
    "# On a side note, I am NOT responsible if your CPU burns itself to death 🔥 \n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def get_lemmatizer(input_string):\n",
    "    return \" \".join(lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(input_string))\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['Review'] = pool.map(get_lemmatizer, amazon_reviews['Review'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['Title'] = pool.map(get_lemmatizer, amazon_reviews['Title'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77e010",
   "metadata": {},
   "source": [
    "Next, let's use a dictionary-based method to get counts of terms which are generally accepted to be positive and negative. I like the VADER dictionary, which not only classifies sentences into positive and negative categories, but also assigns weight based on the magnitude of positivity or negativity. Sometimes you can get unexpected results, as we may see in the next output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a04be1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>ReviewDictionarySent</th>\n",
       "      <th>TitleDictionarySent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>sign hideous scifi film ever watch</td>\n",
       "      <td>disappoint scifi film ever watchedyou alien te...</td>\n",
       "      <td>-0.9517</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>mukluks</td>\n",
       "      <td>comfy make well hop sock different size tend t...</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>great</td>\n",
       "      <td>barbara delinski great author book one bad cou...</td>\n",
       "      <td>-0.2937</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>booring bugggery</td>\n",
       "      <td>bun buggery brutality booring littery device u...</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>houseboy</td>\n",
       "      <td>movie fair entertain great movie look movie wo...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                               Title  \\\n",
       "0  Negative  sign hideous scifi film ever watch   \n",
       "1  Negative                             mukluks   \n",
       "2  Negative                               great   \n",
       "3  Negative                    booring bugggery   \n",
       "4  Negative                            houseboy   \n",
       "\n",
       "                                              Review  ReviewDictionarySent  \\\n",
       "0  disappoint scifi film ever watchedyou alien te...               -0.9517   \n",
       "1  comfy make well hop sock different size tend t...                0.8625   \n",
       "2  barbara delinski great author book one bad cou...               -0.2937   \n",
       "3  bun buggery brutality booring littery device u...                0.1027   \n",
       "4  movie fair entertain great movie look movie wo...                0.8271   \n",
       "\n",
       "   TitleDictionarySent  \n",
       "0               0.0000  \n",
       "1               0.0000  \n",
       "2               0.6249  \n",
       "3               0.0000  \n",
       "4               0.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "def sentiment_scores(review_text):\n",
    "    sentiment_dict = sid_obj.polarity_scores(review_text)\n",
    "    return sentiment_dict['compound']\n",
    "\n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['ReviewDictionarySent'] = pool.map(sentiment_scores, amazon_reviews['Review'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "with mp.Pool(mp.cpu_count()) as pool:  # Processing in parallel\n",
    "    amazon_reviews['TitleDictionarySent'] = pool.map(sentiment_scores, amazon_reviews['Title'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f475c764",
   "metadata": {},
   "source": [
    "Finally, now that our text is as processed as it can be before vectorization, the last step is, of course, vectornization. We'll use the TfidfVectorizer from sklearn, which numerically transforms words based on their originality. There's a bit of math going on here, so check out https://www.analyticsvidhya.com/blog/2021/11/how-sklearns-tfidfvectorizer-calculates-tf-idf-values/ for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b34c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "                       max_df=0.95,\n",
    "                       min_df=0.05,\n",
    "                       ngram_range=(1,3))\n",
    "\n",
    "reviews_unprocessed = tfidf.fit_transform(amazon_reviews['Review'])\n",
    "titles_unprocessed = tfidf.fit_transform(amazon_reviews['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba2119",
   "metadata": {},
   "source": [
    "The text of the reviews and titles has now been transformed into a numeric form. Finally, we need to transform this numeric form into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f22147",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_processed = reviews_unprocessed.toarray()  # Transforming reviews into NumPy array\n",
    "titles_processed = titles_unprocessed.toarray()  # Transforming titles into NumPy array\n",
    "sentiment_array = amazon_reviews[['ReviewDictionarySent','TitleDictionarySent']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a697c9",
   "metadata": {},
   "source": [
    "## Step 2: Machine Learning Classifications\n",
    "\n",
    "Now we can begin to see if we can classify text. First, we will split our data into testing and training sets along an 80/20 split. From there, we will use an AdaBoost, a Random Forest, and an Artificial Neural Network to attempt to make these classifications. Results of these predictions will be reported though confusion matrices. At the end, we will use a stacked ensemble of these three models to see if they can all work well together.\n",
    "\n",
    "First, let's import some preprocessing modules, separate our features and our target variable, and split our data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a91ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Allows us to split into testing and training sets quite easily\n",
    "from sklearn.preprocessing import StandardScaler # Allows easy scaling for training data\n",
    "from sklearn.pipeline import make_pipeline  # Allows use of make_pipeline function\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report,confusion_matrix # Different metrics to score against\n",
    "\n",
    "features = np.concatenate((reviews_processed, titles_processed, sentiment_array), axis=1)  # Concatenating column-wise\n",
    "target = amazon_reviews['Sentiment']  # This is the data we are attempting to predict\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "        features, target.values, test_size=0.20, random_state=123) # I am setting a 80/20 split and setting a seed so my results are consistent in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a540b",
   "metadata": {},
   "source": [
    "First let's build our AdaBoost classifier. In this model (or should I say models), the model is improved by training different models. In each sequence, the following model learns from the last. This model can take a while, so use this time to grab yourself a snack or a cup of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa41cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.77      0.76      0.77     49955\n",
      "    Positive       0.77      0.78      0.77     50045\n",
      "\n",
      "    accuracy                           0.77    100000\n",
      "   macro avg       0.77      0.77      0.77    100000\n",
      "weighted avg       0.77      0.77      0.77    100000\n",
      "\n",
      "[[38161 11794]\n",
      " [11244 38801]]\n",
      "True Negatives:  38161\n",
      "False Positives:  11794\n",
      "False Negatives:  11244\n",
      "True Positives:  38801\n",
      "Accuracy Score 0.76962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "clf_AB = make_pipeline(StandardScaler(),AdaBoostClassifier(tree.DecisionTreeClassifier(class_weight=\"balanced\"),\n",
    "                         algorithm=\"SAMME.R\",\n",
    "                         random_state=123))\n",
    "\n",
    "\n",
    "#Train\n",
    "clf_AB.fit(features_train, target_train)\n",
    "\n",
    "#Validate\n",
    "target_predicted=clf_AB.predict(features_test)\n",
    "print(classification_report(target_test, target_predicted))\n",
    "print(confusion_matrix(target_test, target_predicted))\n",
    "#extracting true_positives, false_positives, true_negatives, false_negatives\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, target_predicted).ravel()\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)\n",
    "print(\"Accuracy Score\", accuracy_score(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca6478",
   "metadata": {},
   "source": [
    "Okay, not bad. Overall, the accuracy is pretty good, The precision, recall, and F1 scores are all also generally consistent. The balance between the classes is also roughly balanced.\n",
    "\n",
    "Let's see if we can improve, however. One of my favorite algorithms is the classic Random Forest. There are just so many things I love about this algorithm; its power and its simplicity, its ability to run in parallel, and, honestly, it just has a cool name. Let's see if we can improve our predictive performance over our AdaBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26e8bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.81      0.81     49955\n",
      "    Positive       0.81      0.80      0.80     50045\n",
      "\n",
      "    accuracy                           0.81    100000\n",
      "   macro avg       0.81      0.81      0.81    100000\n",
      "weighted avg       0.81      0.81      0.81    100000\n",
      "\n",
      "[[40600  9355]\n",
      " [10064 39981]]\n",
      "True Negatives:  40600\n",
      "False Positives:  9355\n",
      "False Negatives:  10064\n",
      "True Positives:  39981\n",
      "Accuracy Score 0.80581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier # A random forest is a very large collection of decision trees that votes on the result.\n",
    "clf_RF = RandomForestClassifier(criterion='gini',\n",
    "                                     n_estimators=100, # I like a lot of trees in my forest\n",
    "                                     random_state=123,\n",
    "                                     n_jobs=-1) # Seeing what happens if I use all processing cores; so much faster\n",
    "\n",
    "\n",
    "clf_RF.fit(features_train, target_train)\n",
    "\n",
    "#Validate\n",
    "target_predicted = clf_RF.predict(features_test)\n",
    "print(classification_report(target_test, target_predicted))\n",
    "print(confusion_matrix(target_test, target_predicted))\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, target_predicted).ravel()\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)\n",
    "print(\"Accuracy Score\", accuracy_score(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2241b7",
   "metadata": {},
   "source": [
    "It looks like the Random Forest did a bit better than the AdaBoost model, coming in at 81 percent accuracy overall with precision, recall, and F1 scores to match. This is our better model so far, but can the artificial neural network perform better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "552a7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.81      0.81     49955\n",
      "    Positive       0.81      0.81      0.81     50045\n",
      "\n",
      "    accuracy                           0.81    100000\n",
      "   macro avg       0.81      0.81      0.81    100000\n",
      "weighted avg       0.81      0.81      0.81    100000\n",
      "\n",
      "[[40381  9574]\n",
      " [ 9619 40426]]\n",
      "True Negatives:  40381\n",
      "False Positives:  9574\n",
      "False Negatives:  9619\n",
      "True Positives:  40426\n",
      "Accuracy Score 0.80807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_ANN = make_pipeline(StandardScaler(),MLPClassifier(solver=\"adam\", learning_rate=\"adaptive\", max_iter=1000,\n",
    "                                                        random_state=123, hidden_layer_sizes=(20,15,10,5))) # I am making this one more complex to hopefully pick up on more nuance in our data\n",
    "\n",
    "#Train\n",
    "clf_ANN.fit(features_train, target_train)\n",
    "\n",
    "#Validate\n",
    "target_predicted=clf_ANN.predict(features_test)\n",
    "print(classification_report(target_test, target_predicted))\n",
    "print(confusion_matrix(target_test, target_predicted))\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, target_predicted).ravel()\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)\n",
    "print(\"Accuracy Score\", accuracy_score(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a225545",
   "metadata": {},
   "source": [
    "Yes, it looks like the artificial neural network CAN perform better, and in less time as well. The performance improvement is only marginal, but this marginal improvement given its speed makes it a better choice than the Random Forest.\n",
    "\n",
    "Finally, let's combine the models above to see if they can do any better than alone. This can take place through a stacked model which essentially combines multiple models into one. Therefore, the model below will use our AdaBoost classifier, our Random Forest, and our Artificial Neural Network in one. This can take a very long time, but we may see a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf8604e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.81      0.81     49955\n",
      "    Positive       0.81      0.81      0.81     50045\n",
      "\n",
      "    accuracy                           0.81    100000\n",
      "   macro avg       0.81      0.81      0.81    100000\n",
      "weighted avg       0.81      0.81      0.81    100000\n",
      "\n",
      "[[40589  9366]\n",
      " [ 9443 40602]]\n",
      "True Negatives:  40589\n",
      "False Positives:  9366\n",
      "False Negatives:  9443\n",
      "True Positives:  40602\n",
      "Accuracy Score 0.81191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier # Allows us to combine completely different models into one\n",
    "from sklearn.linear_model import LogisticRegression # Makes the final call on a particular observation\n",
    "learner1 = clf_AB # AdaBoost Classifier from Above\n",
    "learner2 = clf_RF # Random Forest Model from Above\n",
    "learner3 = clf_ANN # Artificial Neural Network from Above\n",
    "\n",
    "estimators = [\n",
    "     ('ab', learner1),\n",
    "     ('rf', learner2),\n",
    "     ('ann', learner3)] # List of our estimators\n",
    "\n",
    "\n",
    "stacked_learner = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression(),n_jobs=-1)\n",
    "\n",
    "stacked_learner.fit(features_train, target_train)\n",
    "\n",
    "#Validate\n",
    "target_predicted=stacked_learner.predict(features_test)\n",
    "print(classification_report(target_test, target_predicted))\n",
    "print(confusion_matrix(target_test, target_predicted))\n",
    "tn, fp, fn, tp = confusion_matrix(target_test, target_predicted).ravel()\n",
    "print(\"True Negatives: \",tn)\n",
    "print(\"False Positives: \",fp)\n",
    "print(\"False Negatives: \",fn)\n",
    "print(\"True Positives: \",tp)\n",
    "print(\"Accuracy Score\", accuracy_score(target_test, target_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f8eec",
   "metadata": {},
   "source": [
    "Although our accuracy was slightly better than our Artificial Neural Network, it took so much longer. If a company wanted to use a model like this to make a prediction in real time, maybe a stacked model isn't worth the slight accuracy increase given the time it takes to complete.\n",
    "\n",
    "Overall, I hope you found this notebook useful. I'll be uploading more projects like this to my GitHub page (https://github.com/noahmiller-ds) throughout 2022. My next project will be experimenting with the *Ray* framework, which is supposed to help make distributed computing easy. I think the application here will be using Facebook Prophet across multiple machines to predict the next 30 days of stock prices from the top 1000 US stocks. **Please don't use that example as a get-rich-quick oracle; it's more about demonstrating how models can be distributed as opposed to ensuring the predictions are right, in that case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3ac8a",
   "metadata": {},
   "source": [
    "## Project Information\n",
    "\n",
    "Credit to parts of InputProcessing and entirety of lemmatizer functions: \n",
    "https://erleem.medium.com/nlp-complete-sentiment-analysis-on-amazon-reviews-374e4fea9976\n",
    "\n",
    "Credit to user Olivier Cruchant from StackOverflow for easy parallelization of functions using Base Python:\n",
    "https://stackoverflow.com/questions/45545110/make-pandas-dataframe-apply-use-all-cores\n",
    "\n",
    "System Information:\n",
    "2020 M1 MacBook Pro, 16 GB Unified Memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
